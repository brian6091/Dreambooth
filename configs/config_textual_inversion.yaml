description: textual inversion base configuration
#
pretrained_model_name_or_path: runwayml/stable-diffusion-v1-5
pretrained_vae_name_or_path: null
pretrained_tokenizer_name_or_path: null
revision: null
#
#
train_unet_module_or_class: [ALL] or [attn2, up_blocks, down_blocks]
#train_unet_class: [ALL] or [up_blocks, down_blocks]
# use class name here
#lora_unet_class: [CrossAttention, Attention, GEGLU] or [] or null? 
lora_unet_layer: [Linear]

train_text_module: [ALL] or  or [embedding]
train_text_class: [CLIPAttention]
lora_text_layer: [Linear]

train_text_module_or_class: [ALL] or  or [embedding]
lora_text_layer: [Linear]

lora_unet_rank: 4
lora_text_rank: 4
lora_unet_alpha: 4.0
lora_text_alpha: 4.0
#
#
add_instance_token: true
#
#
instance_token: <cat-toy>
instance_prompt: a photo of {}
instance_data_dir: /content/gdrive/MyDrive/cat_statue
prompt_templates: object
class_data_dir: null
class_token: toy
class_prompt: a photo of a toy
with_prior_preservation: false
prior_loss_weight: 1.0
num_class_images: 1500
use_image_captions: false
#
#
conditioning_dropout_prob: 0.0
unconditional_prompt: ' '
clip_skip: null
#
#
augment_output_dir: null
augment_min_resolution: null
augment_center_crop: false
augment_hflip: false
#
#
seed: 1275017
ADD enable_full_determinism: False
resolution: 512
mixed_precision: fp16
train_batch_size: 4
max_train_steps: 10000
gradient_accumulation_steps: 1
gradient_checkpointing: false
#
#
loss: mse
optimizer: AdamW8bit
#use_8bit_adam: true
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 0.01
adam_epsilon: 1.0e-08
max_grad_norm: 1.0
#
#
learning_rate: null
learning_rate_text: 5.0e-04
scale_lr: false
lr_scheduler: cosine
lr_warmup_steps: 50
lr_cosine_num_cycles: 5.0
####
lr_unet_scheduler: cosine
lr_text_scheduler: cosine
lr_unet: null
lr_text: 5.0e-04
lr_scale: false
lr_unet_warmup_steps: 50
lr_text_warmup_steps: 50
lr_unet_cosine_num_cycles: 5.0
lr_text_cosine_num_cycles: 5.0
ADD lr_unet_scheduler_start_iter? for pivotal tuning
ADD lr_unet_scheduler_end_iter?

####
#
#
use_ema: false
ema_inv_gamma: 1.0
ema_power: 0.75
ema_min_value: 0.0
ema_max_value: 0.9999
#
#
output_dir: /content/models/
logging_dir: /content/logs/
#
#
save_n_sample: 4
save_sample_prompt: a photo of {} // a photo of {} holding a mug // an painting of {} by Picasso
save_sample_negative_prompt: hands, border
save_seed: null
save_batch_size: 4 -> sample_batch_size and move to class above
save_interval: 200
save_min_steps: 200
save_guidance_scale: 7.5
save_infer_steps: 50
#
#
hub_token: null
hub_model_id: null
push_to_hub: false
#
#
local_rank: -1
#
#
log_gpu: true
debug: false
